{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlAocOKN4Z2C"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYkH5y3Qzckz"
      },
      "source": [
        "# Translation Models\n",
        "\n",
        "\n",
        "Machine translation is a pivotal field within natural language processing (NLP) that focuses on automating the conversion of text or speech from one language to another. It relies on sophisticated models and techniques to accomplish this challenging task effectively. One of the cornerstone methods in machine translation is the sequence-to-sequence (seq2seq) model, which employs deep neural networks to encode input text and then decode it into the target language. This technique has revolutionized translation tasks by learning to capture complex linguistic nuances and contextual information. Additionally, other models like Transformer-based models, including the famous BERT and GPT-3, have also made significant strides in translation, leveraging attention mechanisms to excel in various language pairs and domains. The choice of model depends on specific translation requirements, language pairs, and the quality of available training data. In this Colab file, we havee given a basic demo on how tto use the dataset and work on a simple seq2seq moel usig RNN.Your task will be to improve the model to the maximum you can ,make prediction on the test dataset given and write a code to generate the BLEU score of you prediction compared to original.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Importing Libraries"
      ],
      "metadata": {
        "id": "s3U_EJucPXrc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nS1d9rgev8J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,LSTM, Dropout,Attention\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Loading and pre-processing the data"
      ],
      "metadata": {
        "id": "1qTHWrDtPdeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Loading the dataset"
      ],
      "metadata": {
        "id": "PgN5wPEJPqud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbtD0ux5ew7d"
      },
      "outputs": [],
      "source": [
        "#Loading and processing data\n",
        "eng_fr = pd.read_csv(\"/content/nlp_intel_train.csv\")\n",
        "eng_fr_test = pd.read_csv(\"/content/nlp_intel_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B) Dropping NaN texts"
      ],
      "metadata": {
        "id": "RONlgjFoPiaA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs9CABoPfty1"
      },
      "outputs": [],
      "source": [
        "eng_fr = eng_fr.dropna(axis=0, how=\"any\", subset=None, inplace=False)\n",
        "eng_fr_test = eng_fr_test.dropna(axis=0, how=\"any\", subset=None, inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C) Removing non-alphabetic characters"
      ],
      "metadata": {
        "id": "NHT3gBJLP_49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: x.lower())\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: x.lower())\n",
        "\n",
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: re.sub(\"'\",\"\",x))\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: re.sub(\"'\",\"\",x))\n",
        "\n",
        "exclude=set(string.punctuation)\n",
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "\n",
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: re.sub(\"[1234567890]\",\"\",x))\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: re.sub(\"[1234567890]\",\"\",x))\n",
        "\n",
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: x.strip())\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: x.strip())\n",
        "\n",
        "eng_fr[\"en\"]=eng_fr[\"en\"].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "eng_fr[\"fr\"]=eng_fr[\"fr\"].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "\n",
        "eng_fr"
      ],
      "metadata": {
        "id": "Nh7t1En30U0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c1621f48-a30d-489b-fdde-26c891f1cc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                                 en  \\\n",
              "0            1000  in he founded the astronomy club of rimouski i...   \n",
              "1            1001  the club was very active and they twice organi...   \n",
              "2            1002  in lemay initiated the first joint meeting of ...   \n",
              "3            1003  the conference took place in quebec city and w...   \n",
              "4            1004  from to he was the national president of the r...   \n",
              "...           ...                                                ...   \n",
              "17995       18995  imports of shrimp and prawn recorded also a sh...   \n",
              "17996       18996  the volume of import decreased by from mt in t...   \n",
              "17997       18997  the market for northern shrimp pandalus boreal...   \n",
              "17998       18998  imports of molluscs almost of this being surf ...   \n",
              "17999       18999  of the group other than finfish and crustacean...   \n",
              "\n",
              "                                                      fr  \n",
              "0      en il fonde le club dastronomie de rimouski au...  \n",
              "1      le club est très actif et organise à deux occa...  \n",
              "2      en il est linstigateur à québec du congrès ann...  \n",
              "3      le congrès est un franc succès et regroupe pas...  \n",
              "4      de à il est président national de la société r...  \n",
              "...                                                  ...  \n",
              "17995  en une forte baisse des importations japonaise...  \n",
              "17996  en effet entre et le volume des importations a...  \n",
              "17997  de plus le marché mondial des crevettes nordiq...  \n",
              "17998  entre et les importations de mollusques dont l...  \n",
              "17999  parmi les produits autres que les poissons à n...  \n",
              "\n",
              "[17999 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f0c49ee-34fb-411b-839e-c2c751731ed9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>in he founded the astronomy club of rimouski i...</td>\n",
              "      <td>en il fonde le club dastronomie de rimouski au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>the club was very active and they twice organi...</td>\n",
              "      <td>le club est très actif et organise à deux occa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1002</td>\n",
              "      <td>in lemay initiated the first joint meeting of ...</td>\n",
              "      <td>en il est linstigateur à québec du congrès ann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1003</td>\n",
              "      <td>the conference took place in quebec city and w...</td>\n",
              "      <td>le congrès est un franc succès et regroupe pas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004</td>\n",
              "      <td>from to he was the national president of the r...</td>\n",
              "      <td>de à il est président national de la société r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>18995</td>\n",
              "      <td>imports of shrimp and prawn recorded also a sh...</td>\n",
              "      <td>en une forte baisse des importations japonaise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>18996</td>\n",
              "      <td>the volume of import decreased by from mt in t...</td>\n",
              "      <td>en effet entre et le volume des importations a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>18997</td>\n",
              "      <td>the market for northern shrimp pandalus boreal...</td>\n",
              "      <td>de plus le marché mondial des crevettes nordiq...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>18998</td>\n",
              "      <td>imports of molluscs almost of this being surf ...</td>\n",
              "      <td>entre et les importations de mollusques dont l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17999</th>\n",
              "      <td>18999</td>\n",
              "      <td>of the group other than finfish and crustacean...</td>\n",
              "      <td>parmi les produits autres que les poissons à n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17999 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f0c49ee-34fb-411b-839e-c2c751731ed9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f0c49ee-34fb-411b-839e-c2c751731ed9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f0c49ee-34fb-411b-839e-c2c751731ed9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cbb3650-df30-4e8b-b763-f66c9e7899ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cbb3650-df30-4e8b-b763-f66c9e7899ed')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cbb3650-df30-4e8b-b763-f66c9e7899ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D) Making a list of all sentences"
      ],
      "metadata": {
        "id": "XYZm-Kc7QNmA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XltalkhYO32R"
      },
      "outputs": [],
      "source": [
        "X=eng_fr[\"en\"].tolist()\n",
        "Y=eng_fr[\"fr\"].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E) Functions for pre-processing the sentences"
      ],
      "metadata": {
        "id": "9HrVfc8EQWgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Function to make a corpus from the available sentences\n",
        "\n"
      ],
      "metadata": {
        "id": "XWDbf6gwQj9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzboP5K41eUD"
      },
      "outputs": [],
      "source": [
        "def to_corpus(sent_list):\n",
        "  text_corpus=\"\"\n",
        "  for sentence in sent_list:\n",
        "    text_corpus+=sentence.lower()+\" \"\n",
        "  return text_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Function to train the tokenizer"
      ],
      "metadata": {
        "id": "hClKUU9rQsMd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YJhb4zR3P3U"
      },
      "outputs": [],
      "source": [
        "def train_tokenizer(file_path):\n",
        "  tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
        "  trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "  tokenizer.pre_tokenizer = Whitespace()\n",
        "  files=[file_path]\n",
        "  tokenizer.train(files, trainer)\n",
        "  tokenizer.post_processor = TemplateProcessing(single=\"[CLS] $A [SEP]\", pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",special_tokens=[(\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),(\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),],)\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Function to form sequence of integers for each sentence"
      ],
      "metadata": {
        "id": "BMT13TCMQ1v0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLmqfOFO58wH"
      },
      "outputs": [],
      "source": [
        "def sequences(tokenizer,sent_list):\n",
        "  prepoc_sentences=[]\n",
        "  for sent in sent_list:\n",
        "    encoding=tokenizer.encode(sent.lower())\n",
        "    prepoc_sentences.append(encoding.ids)\n",
        "  prepoc_sentences = pad_sequences(prepoc_sentences,55, padding='post')\n",
        "  prepoc_sentences=np.array(prepoc_sentences)\n",
        "  return prepoc_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Function to form a dictionary of words"
      ],
      "metadata": {
        "id": "e7g71mUxSUWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYKMV-13xOBl"
      },
      "outputs": [],
      "source": [
        "def vocabulary(path_vocab):\n",
        "    import json\n",
        "    f=open(path_vocab)\n",
        "    vocab=json.load(f)\n",
        "    dict_vocab={}\n",
        "    for i in vocab[\"model\"][\"vocab\"]:\n",
        "        dict_vocab[vocab[\"model\"][\"vocab\"][i]]= i\n",
        "    return dict_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F) Making a corpus out of the sentences"
      ],
      "metadata": {
        "id": "B_wmZnnIQ8IG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5scfSlq5Bbm",
        "outputId": "b996b910-181d-4276-8063-011dabd10503"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2368969"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "f1=open(\"x.txt\",\"w\")\n",
        "f1.write(to_corpus(X))\n",
        "\n",
        "f2=open(\"y.txt\",\"w\")\n",
        "f2.write(to_corpus(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G) Training and saving the tokenizer with the corpus made"
      ],
      "metadata": {
        "id": "x45gbNuURLoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqPjHCho40SM"
      },
      "outputs": [],
      "source": [
        "tokenizer_eng,tokenizer_fr=train_tokenizer(\"/content/x.txt\"),train_tokenizer(\"/content/y.txt\")\n",
        "tokenizer_eng.save(\"english_vocab.json\",pretty=True)\n",
        "tokenizer_fr.save(\"french_vocab.json\",pretty=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### H) Forming a sequence for each sentence"
      ],
      "metadata": {
        "id": "cMBVVzl1Rh9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Zsr8Ql6uLf"
      },
      "outputs": [],
      "source": [
        "prepoc_english_sentences,prepoc_french_sentences=sequences(tokenizer_eng,X),sequences(tokenizer_fr,Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I) Creating a dictionary of words and ids"
      ],
      "metadata": {
        "id": "dsSDgmuwRy5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhTjDKEVxOBl"
      },
      "outputs": [],
      "source": [
        "dict_eng,dict_fr=vocabulary(\"english_vocab.json\"),vocabulary(\"french_vocab.json\")\n",
        "vocabulary_size_english=tokenizer_eng.get_vocab_size()\n",
        "vocabulary_size_french=tokenizer_fr.get_vocab_size()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Building and Training the se2seq model"
      ],
      "metadata": {
        "id": "pFZghHC7SlPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Building the model"
      ],
      "metadata": {
        "id": "p3nRMeGjS21X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size_fr,vocab_size_eng):\n",
        "    learning_rate=0.003\n",
        "    model=Sequential()\n",
        "    model.add(Embedding(vocab_size_fr,256))\n",
        "    model.add(Bidirectional(GRU(256,return_sequences=True)))  #Bidirectional LSTM would be better\n",
        "    model.add(Dense(1024, activation='selu'))\n",
        "    model.add(Dropout(0.5))                                   #Adding an attention layer will also optimise the model\n",
        "    model.add(Bidirectional(GRU(512,return_sequences=True)))\n",
        "    model.add(Dense(1024, activation='selu'))\n",
        "    model.add(Dense(vocab_size_eng, activation='softmax'))\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BPd1vLXi2QJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B) Training the model"
      ],
      "metadata": {
        "id": "AtlYKG5SS8FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = pad_sequences(prepoc_french_sentences, maxlen = 55, padding = 'post')\n",
        "model = build_model(vocabulary_size_french,vocabulary_size_english)\n",
        "model.summary()\n",
        "model.fit(tmp_x, prepoc_english_sentences, batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "metadata": {
        "id": "O7k5eev-qRkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Predictions"
      ],
      "metadata": {
        "id": "nngrbVgfTBC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Function to Convert sequence to sentence"
      ],
      "metadata": {
        "id": "2QQ1aY2sTFIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HarkZpzPxOBm"
      },
      "outputs": [],
      "source": [
        "def logits_to_text(logits,dict_lan):\n",
        "  pred=[prediction for prediction in np.argmax(logits, 1)]\n",
        "  while pred[-1]==0:\n",
        "    pred.pop(-1)\n",
        "  return ' '.join([dict_lan[prediction] for prediction in pred])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B) Prediction from training set"
      ],
      "metadata": {
        "id": "eiu42iqjTTcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i= 1\n",
        "\n",
        "print(\"Prediction:\")\n",
        "test_val=logits_to_text(model.predict(tmp_x[[i]])[0], dict_eng)\n",
        "print(test_val)\n",
        "print(\"\\nCorrect Translation:\")\n",
        "actual_val=X[i]\n",
        "print(X[i])\n",
        "print(\"\\nOriginal text:\")\n",
        "print(Y[i])"
      ],
      "metadata": {
        "id": "Ez8TfRzMr95J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C) Testing set - preprocessing and prediction."
      ],
      "metadata": {
        "id": "aSVMjVxAa-ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: x.lower())\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: x.lower())\n",
        "\n",
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: re.sub(\"'\",\"\",x))\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: re.sub(\"'\",\"\",x))\n",
        "\n",
        "exclude=set(string.punctuation)\n",
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "\n",
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: re.sub(\"[1234567890]\",\"\",x))\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: re.sub(\"[1234567890]\",\"\",x))\n",
        "\n",
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: x.strip())\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: x.strip())\n",
        "\n",
        "eng_fr_test[\"en\"]=eng_fr_test[\"en\"].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "eng_fr_test[\"fr\"]=eng_fr_test[\"fr\"].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "\n",
        "eng_fr_test"
      ],
      "metadata": {
        "id": "Q-G-1Mr-9lqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=eng_fr_test[\"en\"].tolist()\n",
        "Y_test=eng_fr_test[\"fr\"].tolist()"
      ],
      "metadata": {
        "id": "Y3j2MTLX-q7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_english_sentences,test_french_sentences=sequences(tokenizer_eng,X_test),sequences(tokenizer_fr,Y_test)"
      ],
      "metadata": {
        "id": "6Jk2uvYe--Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_test = pad_sequences(test_french_sentences, maxlen = 55, padding = 'post')\n",
        "i= 1998\n",
        "\n",
        "print(\"Prediction:\")\n",
        "test_val=logits_to_text(model.predict(tmp_test[[i]])[0], dict_eng)\n",
        "print(test_val)\n",
        "print(\"\\nCorrect Translation:\")\n",
        "actual_val=X_test[i]\n",
        "print(X_test[i])\n",
        "print(\"\\nOriginal text:\")\n",
        "print(Y_test[i])"
      ],
      "metadata": {
        "id": "MDVCtQhMygTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Metrics"
      ],
      "metadata": {
        "id": "RJHrd4NfXp3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "hypothesis = test_val.split()\n",
        "reference = actual_val.split()\n",
        "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
        "print(BLEUscore)\n"
      ],
      "metadata": {
        "id": "miFTGN6tZMlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb255fa-3d2e-44ed-b582-89de2fb321a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1297213512319855e-78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}